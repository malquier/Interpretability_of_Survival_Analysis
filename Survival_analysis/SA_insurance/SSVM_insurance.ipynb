{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Standard ML import\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import optuna\n",
    "\n",
    "# Survival Analysis tools\n",
    "\n",
    "from sksurv.svm import FastSurvivalSVM,FastKernelSurvivalSVM\n",
    "from sksurv.metrics import concordance_index_censored,cumulative_dynamic_auc,concordance_index_ipcw\n",
    "from sksurv.datasets import get_x_y\n",
    "from lifelines import CoxPHFitter\n",
    "from survlimepy import SurvLimeExplainer\n",
    "\n",
    "# Interpretability tools\n",
    "\n",
    "import shap\n",
    "import lime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>pren_prod</th>\n",
       "      <th>pren_comp</th>\n",
       "      <th>sex_0</th>\n",
       "      <th>sex_1</th>\n",
       "      <th>smoker_0</th>\n",
       "      <th>smoker_1</th>\n",
       "      <th>point_sales_0</th>\n",
       "      <th>point_sales_1</th>\n",
       "      <th>point_sales_2</th>\n",
       "      <th>...</th>\n",
       "      <th>pay_freq_2</th>\n",
       "      <th>pay_freq_3</th>\n",
       "      <th>pay_method_0</th>\n",
       "      <th>pay_method_1</th>\n",
       "      <th>pay_method_2</th>\n",
       "      <th>profession_0</th>\n",
       "      <th>profession_1</th>\n",
       "      <th>profession_2</th>\n",
       "      <th>evento</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>780.00</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>52.78</td>\n",
       "      <td>16.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>757.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>63.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>19.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>351.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>632.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  pren_prod  pren_comp  sex_0  sex_1  smoker_0  smoker_1  point_sales_0  \\\n",
       "0   40     780.00       1.88    1.0    0.0       0.0       1.0            0.0   \n",
       "1   43      52.78      16.88    0.0    1.0       0.0       1.0            1.0   \n",
       "2   52      63.50       0.00    1.0    0.0       0.0       1.0            1.0   \n",
       "3   25      19.10       0.00    0.0    1.0       0.0       1.0            0.0   \n",
       "4   51     351.00       0.00    1.0    0.0       0.0       1.0            1.0   \n",
       "\n",
       "   point_sales_1  point_sales_2  ...  pay_freq_2  pay_freq_3  pay_method_0  \\\n",
       "0            1.0            0.0  ...         0.0         1.0           0.0   \n",
       "1            0.0            0.0  ...         0.0         1.0           0.0   \n",
       "2            0.0            0.0  ...         0.0         1.0           0.0   \n",
       "3            1.0            0.0  ...         0.0         1.0           0.0   \n",
       "4            0.0            0.0  ...         0.0         1.0           0.0   \n",
       "\n",
       "   pay_method_1  pay_method_2  profession_0  profession_1  profession_2  \\\n",
       "0           1.0           0.0           0.0           0.0           1.0   \n",
       "1           1.0           0.0           0.0           1.0           0.0   \n",
       "2           1.0           0.0           0.0           1.0           0.0   \n",
       "3           1.0           0.0           0.0           1.0           0.0   \n",
       "4           1.0           0.0           0.0           1.0           0.0   \n",
       "\n",
       "   evento   time  \n",
       "0   False  609.0  \n",
       "1    True  757.0  \n",
       "2    True  672.0  \n",
       "3    True  407.0  \n",
       "4    True  632.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset Insurance\n",
    "\n",
    "data_ins = pd.read_csv(\"X_train.csv\")\n",
    "ins_credit = pd.read_csv(\"y_train.csv\")\n",
    "\n",
    "data_ins.rename(columns = {'0':'age','1':'sex', '2':'smoker', '3':'pren_prod', '4':'pren_comp', '5':'point_sales', '6': 'product_type', '7': 'dist_channel', '8': 'pay_freq', '9': 'pay_method', '10':'profession'}, inplace = True)\n",
    "#data_ins.info()\n",
    "\n",
    "# Categorical columns\n",
    "colonnes_categorielles = ['sex', 'smoker', 'point_sales', 'product_type', 'dist_channel', 'pay_freq', 'pay_method', 'profession']\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(data_ins[colonnes_categorielles])\n",
    "\n",
    "ins_encodees = encoder.fit_transform(data_ins[colonnes_categorielles]).toarray()\n",
    "nouveaux_noms_colonnes = encoder.get_feature_names_out(colonnes_categorielles)\n",
    "ins_encodees_df = pd.DataFrame(ins_encodees, columns=nouveaux_noms_colonnes)\n",
    "ins_features = data_ins.drop(columns=colonnes_categorielles).join(ins_encodees_df)\n",
    "\n",
    "df = pd.concat([ins_features, ins_credit], axis=1).drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split\n",
    "\n",
    "X,y = get_x_y(df,attr_labels=['evento','time'],pos_label=1,survival=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cox model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column pay_freq_2 have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
      "\n",
      ">>> events = df['evento'].astype(bool)\n",
      ">>> print(df.loc[events, 'pay_freq_2'].var())\n",
      ">>> print(df.loc[~events, 'pay_freq_2'].var())\n",
      "\n",
      "A very low variance means that the column pay_freq_2 completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
      "\n",
      "Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.833. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     coef      exp(coef)     se(coef)  coef lower 95%  \\\n",
      "covariate                                                               \n",
      "age             -0.016703       0.983436     0.001707       -0.020048   \n",
      "pren_prod       -0.000067       0.999933     0.000040       -0.000146   \n",
      "pren_comp        0.000019       1.000019     0.000035       -0.000049   \n",
      "sex_0            0.051223       1.052558     0.030154       -0.007878   \n",
      "smoker_0         0.123510       1.131462     0.059156        0.007567   \n",
      "point_sales_0   -0.081251       0.921963     0.149570       -0.374402   \n",
      "point_sales_1    0.225333       1.252740     0.148428       -0.065580   \n",
      "point_sales_2    0.123760       1.131744     0.155332       -0.180685   \n",
      "point_sales_3    0.136406       1.146147     0.157428       -0.172147   \n",
      "product_type_0  13.160883  519635.816486   248.101464     -473.109051   \n",
      "product_type_1  13.015335  449250.067323   248.101470     -473.254610   \n",
      "product_type_2  12.810163  365917.412999   248.101455     -473.459754   \n",
      "product_type_3  13.033721  457586.325165   248.101460     -473.236205   \n",
      "product_type_4  12.192430  197290.005224   248.103465     -474.081425   \n",
      "product_type_5   0.292259       1.339450  1029.587110    -2017.661396   \n",
      "product_type_6  -0.032447       0.968074  1136.350413    -2227.238330   \n",
      "product_type_7  12.954964  422931.012422   248.101453     -473.314948   \n",
      "product_type_8  12.734964  339409.801736   248.101453     -473.534949   \n",
      "product_type_9  13.080773  479631.255224   248.101701     -473.189625   \n",
      "dist_channel_0  -0.301400       0.739782     0.467098       -1.216896   \n",
      "dist_channel_1  -0.579737       0.560046     0.456566       -1.474590   \n",
      "dist_channel_2  -0.214197       0.807189     0.455951       -1.107845   \n",
      "dist_channel_3   0.004133       1.004141     0.465470       -0.908172   \n",
      "pay_freq_0       0.016831       1.016973     0.059687       -0.100154   \n",
      "pay_freq_1      -0.117337       0.889285     0.050896       -0.217091   \n",
      "pay_freq_2       0.769045       2.157704     0.713001       -0.628411   \n",
      "pay_method_0    -1.599766       0.201944     0.709873       -2.991092   \n",
      "pay_method_1    -2.063786       0.126972     0.708645       -3.452705   \n",
      "profession_0     0.250713       1.284942     0.074122        0.105437   \n",
      "profession_1    -0.207614       0.812521     0.037424       -0.280963   \n",
      "\n",
      "                coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%  \\\n",
      "covariate                                                                  \n",
      "age                  -0.013357         9.801513e-01         9.867315e-01   \n",
      "pren_prod             0.000012         9.998544e-01         1.000012e+00   \n",
      "pren_comp             0.000087         9.999508e-01         1.000087e+00   \n",
      "sex_0                 0.110325         9.921528e-01         1.116641e+00   \n",
      "smoker_0              0.239454         1.007596e+00         1.270555e+00   \n",
      "point_sales_0         0.211900         6.877005e-01         1.236025e+00   \n",
      "point_sales_1         0.516245         9.365242e-01         1.675724e+00   \n",
      "point_sales_2         0.428205         8.346980e-01         1.534500e+00   \n",
      "point_sales_3         0.444959         8.418551e-01         1.560426e+00   \n",
      "product_type_0      499.430818        3.398989e-206        7.944167e+216   \n",
      "product_type_1      499.285280        2.938557e-206        6.868187e+216   \n",
      "product_type_2      499.080080        2.393543e-206        5.594031e+216   \n",
      "product_type_3      499.303646        2.993145e-206        6.995493e+216   \n",
      "product_type_4      498.466285        1.285444e-206        3.028008e+216   \n",
      "product_type_5     2018.245914         0.000000e+00                  inf   \n",
      "product_type_6     2227.173437         0.000000e+00                  inf   \n",
      "product_type_7      499.224877        2.766494e-206        6.465608e+216   \n",
      "product_type_8      499.004876        2.220161e-206        5.188768e+216   \n",
      "product_type_9      499.351171        3.135862e-206        7.335979e+216   \n",
      "dist_channel_0        0.614095         2.961481e-01         1.847984e+00   \n",
      "dist_channel_1        0.315117         2.288725e-01         1.370419e+00   \n",
      "dist_channel_2        0.679451         3.302699e-01         1.972795e+00   \n",
      "dist_channel_3        0.916437         4.032608e-01         2.500365e+00   \n",
      "pay_freq_0            0.133815         9.046981e-01         1.143182e+00   \n",
      "pay_freq_1           -0.017583         8.048565e-01         9.825702e-01   \n",
      "pay_freq_2            2.166500         5.334385e-01         8.727688e+00   \n",
      "pay_method_0         -0.208440         5.023255e-02         8.118495e-01   \n",
      "pay_method_1         -0.674866         3.165988e-02         5.092244e-01   \n",
      "profession_0          0.395990         1.111196e+00         1.485854e+00   \n",
      "profession_1         -0.134264         7.550561e-01         8.743590e-01   \n",
      "\n",
      "                cmp to         z             p   -log2(p)  \n",
      "covariate                                                  \n",
      "age                0.0 -9.785295  1.302149e-22  72.701524  \n",
      "pren_prod          0.0 -1.658602  9.719608e-02   3.362958  \n",
      "pren_comp          0.0  0.540721  5.886999e-01   0.764396  \n",
      "sex_0              0.0  1.698704  8.937499e-02   3.483985  \n",
      "smoker_0           0.0  2.087883  3.680837e-02   4.763822  \n",
      "point_sales_0      0.0 -0.543230  5.869715e-01   0.768638  \n",
      "point_sales_1      0.0  1.518133  1.289809e-01   2.954770  \n",
      "point_sales_2      0.0  0.796743  4.256001e-01   1.232430  \n",
      "point_sales_3      0.0  0.866464  3.862355e-01   1.372447  \n",
      "product_type_0     0.0  0.053046  9.576950e-01   0.062362  \n",
      "product_type_1     0.0  0.052460  9.581624e-01   0.061658  \n",
      "product_type_2     0.0  0.051633  9.588213e-01   0.060666  \n",
      "product_type_3     0.0  0.052534  9.581033e-01   0.061747  \n",
      "product_type_4     0.0  0.049143  9.608057e-01   0.057683  \n",
      "product_type_5     0.0  0.000284  9.997735e-01   0.000327  \n",
      "product_type_6     0.0 -0.000029  9.999772e-01   0.000033  \n",
      "product_type_7     0.0  0.052216  9.583563e-01   0.061366  \n",
      "product_type_8     0.0  0.051330  9.590628e-01   0.060303  \n",
      "product_type_9     0.0  0.052723  9.579523e-01   0.061974  \n",
      "dist_channel_0     0.0 -0.645261  5.187582e-01   0.946866  \n",
      "dist_channel_1     0.0 -1.269776  2.041645e-01   2.292196  \n",
      "dist_channel_2     0.0 -0.469780  6.385120e-01   0.647214  \n",
      "dist_channel_3     0.0  0.008878  9.929164e-01   0.010256  \n",
      "pay_freq_0         0.0  0.281981  7.779579e-01   0.362236  \n",
      "pay_freq_1         0.0 -2.305444  2.114173e-02   5.563763  \n",
      "pay_freq_2         0.0  1.078603  2.807649e-01   1.832565  \n",
      "pay_method_0       0.0 -2.253594  2.422170e-02   5.367556  \n",
      "pay_method_1       0.0 -2.912297  3.587812e-03   8.122680  \n",
      "profession_0       0.0  3.382442  7.184454e-04  10.442834  \n",
      "profession_1       0.0 -5.547624  2.895786e-08  25.041470  \n"
     ]
    }
   ],
   "source": [
    "# Create Cox model\n",
    "cox_model = CoxPHFitter()\n",
    "\n",
    "# Fit the model, for each categorical feature we drop the last category to avoid multicollinearity\n",
    "cox_model.fit(df.drop(columns=['sex_1','smoker_1','point_sales_4','product_type_10','dist_channel_4','pay_freq_3','pay_method_2','profession_2']), duration_col='time', event_col='evento')\n",
    "\n",
    "# Display the summary of the model\n",
    "print(cox_model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FastKernelSurvivalSVM(degree=5, kernel=&#x27;poly&#x27;, optimizer=&#x27;rbtree&#x27;,\n",
       "                      random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FastKernelSurvivalSVM</label><div class=\"sk-toggleable__content\"><pre>FastKernelSurvivalSVM(degree=5, kernel=&#x27;poly&#x27;, optimizer=&#x27;rbtree&#x27;,\n",
       "                      random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "FastKernelSurvivalSVM(degree=5, kernel='poly', optimizer='rbtree',\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit the survival svm\n",
    "\n",
    "SSVM = FastKernelSurvivalSVM(kernel = 'poly',degree = 5,random_state=42)\n",
    "SSVM.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_index : 0.5159484169877243\n",
      "c_index_ipcw : 0.5141468954482205\n",
      "auc_dynamic : 0.51029445057416\n"
     ]
    }
   ],
   "source": [
    "# define the concordance index\n",
    "\n",
    "def concordance_censored(estimator,X,y):\n",
    "    concordance = concordance_index_censored([elt[0] for elt in y],[elt[1] for elt in y],estimator.predict(X))\n",
    "    return concordance[0]\n",
    "\n",
    "print(f\"c_index : {concordance_censored(SSVM,X_test,y_test)}\")\n",
    "\n",
    "# define the concordance index ipcw\n",
    "\n",
    "concordance_ipcw = concordance_index_ipcw(y_train,y_test,SSVM.predict(X_test))\n",
    "print(f\"c_index_ipcw : {concordance_ipcw[0]}\")\n",
    "\n",
    "# compute the auc dynamic score\n",
    "\n",
    "auc_dynamic = cumulative_dynamic_auc(y_train,y_test,SSVM.predict(X_test),times = np.arange(1, 2059, 30))\n",
    "print(f\"auc_dynamic : {auc_dynamic[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-11 14:43:21,380] A new study created in memory with name: no-name-5d1bb18a-623e-46a3-b2e3-20a989ea4ab9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "[I 2024-04-11 14:43:40,078] Trial 0 finished with value: 0.5052577019700714 and parameters: {'gamma': 0.034606406277004655, 'kernel': 'poly', 'degree': 5}. Best is trial 0 with value: 0.5052577019700714.\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "[I 2024-04-11 14:43:48,926] Trial 1 finished with value: 0.5617466186913036 and parameters: {'gamma': 0.0014422636839047272, 'kernel': 'linear', 'degree': 3}. Best is trial 1 with value: 0.5617466186913036.\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "[I 2024-04-11 14:44:10,425] Trial 2 finished with value: 0.505258751155903 and parameters: {'gamma': 0.0002159752876822909, 'kernel': 'poly', 'degree': 5}. Best is trial 1 with value: 0.5617466186913036.\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "[I 2024-04-11 14:44:32,381] Trial 3 finished with value: 0.5373753331647808 and parameters: {'gamma': 0.00024982405751418157, 'kernel': 'poly', 'degree': 3}. Best is trial 1 with value: 0.5617466186913036.\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "X has feature names, but FastKernelSurvivalSVM was fitted without feature names\n",
      "[I 2024-04-11 14:44:45,226] Trial 4 finished with value: 0.5591031503990749 and parameters: {'gamma': 70.33685044054509, 'kernel': 'poly', 'degree': 2}. Best is trial 1 with value: 0.5617466186913036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'gamma': 0.0014422636839047272, 'kernel': 'linear', 'degree': 3}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters optimization with optuna\n",
    "\n",
    "# We use the concordance index as evaluation metric\n",
    "def scorer(estimator, X, y):\n",
    "    concordance =  concordance_index_censored([elt[0] for elt in y],[elt[1] for elt in y],estimator.predict(X))[0]\n",
    "    return concordance\n",
    "\n",
    "def objective(trial):\n",
    "    # Define search space for hyperparameters\n",
    "    gamma = trial.suggest_float('gamma', 1e-5, 1e3,log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear','poly'])\n",
    "    degree = trial.suggest_int('degree', 2, 5)\n",
    "\n",
    "    \n",
    "    # Initialize model with hyperparameters\n",
    "    model = FastKernelSurvivalSVM(random_state=42, max_iter = 1000, gamma = gamma, kernel = kernel, degree = degree)\n",
    "    \n",
    "    def k_fold_cross_validation(model, X, y, k=5):\n",
    "        \"\"\"\n",
    "        Performs k-fold cross-validation for a given model and dataset.\n",
    "\n",
    "        Parameters:\n",
    "            model: The machine learning model to evaluate.\n",
    "            X (numpy.ndarray): The feature matrix.\n",
    "            y (numpy.ndarray): The target vector.\n",
    "            k (int): Number of folds for cross-validation.\n",
    "\n",
    "        Returns:\n",
    "            float: The average accuracy across all folds.\n",
    "        \"\"\"\n",
    "        n = len(X)\n",
    "        fold_size = n // k\n",
    "        scores = []\n",
    "\n",
    "        for i in range(k):\n",
    "            # Splitting data into training and validation sets\n",
    "            validation_X = X[i * fold_size: (i + 1) * fold_size]\n",
    "            validation_y = y[i * fold_size: (i + 1) * fold_size]\n",
    "            train_X = np.concatenate([X[:i * fold_size], X[(i + 1) * fold_size:]])\n",
    "            train_y = np.concatenate([y[:i * fold_size], y[(i + 1) * fold_size:]])\n",
    "\n",
    "            # Fitting the model\n",
    "            model.fit(train_X, train_y)\n",
    "\n",
    "            # Making predictions on the validation set\n",
    "            y_pred = model.predict(validation_X)\n",
    "\n",
    "            # Calculating accuracy\n",
    "            score = scorer(model, validation_X, validation_y)\n",
    "            scores.append(score)\n",
    "\n",
    "        # Returning the average accuracy\n",
    "        return sum(scores) / k\n",
    "    \n",
    "    return k_fold_cross_validation(model, X_train, y_train, k=5)\n",
    "\n",
    "# Create Optuna study object\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Run optimization\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# Access best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_index : 0.5516833661492369\n"
     ]
    }
   ],
   "source": [
    "# Best ssurvival svm model\n",
    "\n",
    "best_SSVM = FastKernelSurvivalSVM(random_state=42, max_iter = 1000, **best_params)\n",
    "best_SSVM.fit(X_train, y_train)\n",
    "\n",
    "# Compute the concordance index\n",
    "\n",
    "print(f\"c_index : {concordance_censored(best_SSVM,X_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perturbations(instance, num_samples, num_features):\n",
    "    \"\"\"\n",
    "    Generates perturbed instances by randomly perturbing features of the original instance.\n",
    "\n",
    "    Parameters:\n",
    "        instance (numpy.ndarray): The original instance.\n",
    "        num_samples (int): Number of perturbed instances to generate.\n",
    "        num_features (int): Number of features in the instance.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Perturbed instances.\n",
    "    \"\"\"\n",
    "    perturbations = []\n",
    "    for _ in range(num_samples):\n",
    "        perturbation = np.copy(instance)\n",
    "        for i in range(num_features):\n",
    "            perturbation[i] += np.random.normal()\n",
    "        perturbations.append(perturbation)\n",
    "    return perturbations\n",
    "\n",
    "\n",
    "def lime_explanation(instance, model, num_samples=1000):\n",
    "    \"\"\"\n",
    "    Generates LIME explanation for a given instance.\n",
    "\n",
    "    Parameters:\n",
    "        instance (numpy.ndarray): The instance to be explained.\n",
    "        model: The black-box model whose predictions are to be explained.\n",
    "        num_samples (int): Number of perturbed instances to generate for LIME.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Feature importances estimated by LIME.\n",
    "    \"\"\"\n",
    "    num_features = len(instance)\n",
    "    perturbations = generate_perturbations(instance, num_samples, num_features)\n",
    "\n",
    "    predictions = model.predict(perturbations)\n",
    "    local_model = LinearRegression().fit(perturbations, predictions)\n",
    "    return local_model.coef_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts datasets into numpy arrays\n",
    "\n",
    "X_train_np = X_train.to_numpy()\n",
    "X_test_np = X_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME feature importances: [-1.19832443e-06 -6.16639673e-05 -3.19665196e-05 -8.51678193e-09\n",
      " -1.87805284e-08 -2.08926786e-09 -2.52080425e-08 -1.45275528e-08\n",
      " -8.94766392e-09 -2.55244055e-09 -1.21990378e-09 -4.97493085e-11\n",
      " -1.62466246e-09 -3.83103967e-09 -1.73431797e-09 -1.41253515e-09\n",
      " -1.71964486e-10 -1.01309703e-10 -3.93878676e-11 -7.70028572e-09\n",
      " -9.17166548e-09 -9.20728714e-10 -5.89413121e-10 -7.67939935e-10\n",
      " -2.08981619e-08 -5.19501713e-09 -3.41084480e-10 -9.51069316e-11\n",
      " -5.58154482e-09 -7.57398577e-09 -4.77220361e-13 -1.41413025e-08\n",
      " -1.30115232e-08 -1.42819190e-08 -3.86810381e-12 -6.78497254e-10\n",
      " -2.28633375e-08 -3.75547563e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but FastKernelSurvivalSVM was fitted with feature names\n"
     ]
    }
   ],
   "source": [
    "# Explain the first instance in the test set\n",
    "lime_importance = lime_explanation(X_train_np[0], best_SSVM, num_samples=1000)\n",
    "print(\"LIME feature importances:\", lime_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pay_freq_2: 5.0208781708311424e-09\n",
      "pay_method_2: 4.0696666752880527e-08\n",
      "product_type_6: 4.144032843479347e-07\n",
      "point_sales_4: 5.234169324587764e-07\n",
      "dist_channel_4: 1.0006285488000512e-06\n",
      "product_type_5: 1.0658884597851136e-06\n",
      "product_type_4: 1.809253765020148e-06\n",
      "dist_channel_3: 3.5885803775860796e-06\n",
      "product_type_10: 6.201268258186057e-06\n",
      "profession_0: 7.138530398447996e-06\n",
      "dist_channel_0: 8.079564864812326e-06\n",
      "product_type_9: 9.687069289320794e-06\n",
      "point_sales_3: 1.2834716960424274e-05\n",
      "product_type_3: 1.4861408846543925e-05\n",
      "product_type_0: 1.7093219329395266e-05\n",
      "product_type_2: 1.8246914735336828e-05\n",
      "smoker_0: 2.1981374333886725e-05\n",
      "point_sales_2: 2.685445568286959e-05\n",
      "profession_2: 3.95116956158662e-05\n",
      "product_type_1: 4.030671164513502e-05\n",
      "dist_channel_2: 5.465724063754094e-05\n",
      "pay_freq_0: 5.872393313204079e-05\n",
      "pay_freq_1: 7.968658288025819e-05\n",
      "product_type_7: 8.10153959291781e-05\n",
      "sex_0: 8.960582573539726e-05\n",
      "point_sales_1: 9.413917381542535e-05\n",
      "product_type_8: 9.649591426078858e-05\n",
      "pay_method_0: 0.00013689540182327235\n",
      "pay_freq_3: 0.0001487819109554615\n",
      "pay_method_1: 0.00015026134941638962\n",
      "point_sales_0: 0.00015284568442476107\n",
      "sex_1: 0.00019759162213640207\n",
      "dist_channel_1: 0.00021987143346061902\n",
      "profession_1: 0.00024054722185389157\n",
      "smoker_1: 0.00026521607348618657\n",
      "age: 0.012607678669106339\n",
      "pren_comp: 0.3363226165136448\n",
      "pren_prod: 0.6487721252344281\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionnary to map the feature names to the feature importances\n",
    "feature_importances = dict(zip(X.columns, lime_importance))\n",
    "\n",
    "# Sort the feature importances\n",
    "sorted_feature_importances = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Normalize the feature importances\n",
    "total_importance = sum(abs(elt[1]) for elt in sorted_feature_importances)\n",
    "normalized_feature_importances = [(elt[0], abs(elt[1]) / total_importance) for elt in sorted_feature_importances]\n",
    "\n",
    "# Display the normalized feature importances\n",
    "for feature, importance in normalized_feature_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
